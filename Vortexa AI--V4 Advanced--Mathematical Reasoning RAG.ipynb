{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0505afc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/anaconda3/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/anaconda3/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/anaconda3/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/8d/ypv3gmcs6l1b6rxfs4tlhqdm0000gn/T/ipykernel_64928/340707907.py\", line 3, in <module>\n",
      "    from sentence_transformers import SentenceTransformer, util\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sentence_transformers/__init__.py\", line 14, in <module>\n",
      "    from sentence_transformers.cross_encoder.CrossEncoder import CrossEncoder\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sentence_transformers/cross_encoder/__init__.py\", line 3, in <module>\n",
      "    from .CrossEncoder import CrossEncoder\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py\", line 14, in <module>\n",
      "    from transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer, is_torch_npu_available\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/transformers/utils/import_utils.py\", line 2154, in __getattr__\n",
      "    module = self._get_module(self._class_to_module[name])\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/transformers/utils/import_utils.py\", line 2182, in _get_module\n",
      "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
      "  File \"/opt/anaconda3/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/transformers/models/auto/modeling_auto.py\", line 21, in <module>\n",
      "    from .auto_factory import (\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py\", line 43, in <module>\n",
      "    from ...generation import GenerationMixin\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/transformers/utils/import_utils.py\", line 2154, in __getattr__\n",
      "    module = self._get_module(self._class_to_module[name])\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/transformers/utils/import_utils.py\", line 2182, in _get_module\n",
      "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
      "  File \"/opt/anaconda3/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/transformers/generation/utils.py\", line 63, in <module>\n",
      "    from .candidate_generator import (\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/transformers/generation/candidate_generator.py\", line 29, in <module>\n",
      "    from sklearn.metrics import roc_curve\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/__init__.py\", line 73, in <module>\n",
      "    from .base import clone  # noqa: E402\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 19, in <module>\n",
      "    from .utils._metadata_requests import _MetadataRequester, _routing_enabled\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/__init__.py\", line 9, in <module>\n",
      "    from ._chunking import gen_batches, gen_even_slices\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_chunking.py\", line 11, in <module>\n",
      "    from ._param_validation import Interval, validate_params\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 17, in <module>\n",
      "    from .validation import _is_arraylike_not_scalar\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 21, in <module>\n",
      "    from ..utils._array_api import _asarray_with_order, _is_numpy_namespace, get_namespace\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_array_api.py\", line 20, in <module>\n",
      "    from .fixes import parse_version\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/fixes.py\", line 20, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/core/api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/core/arrays/__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/core/arrays/arrow/array.py\", line 52, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/core/ops/__init__.py\", line 8, in <module>\n",
      "    from pandas.core.ops.array_ops import (\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/core/ops/array_ops.py\", line 56, in <module>\n",
      "    from pandas.core.computation import expressions\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/core/computation/expressions.py\", line 21, in <module>\n",
      "    from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/core/computation/check.py\", line 5, in <module>\n",
      "    ne = import_optional_dependency(\"numexpr\", errors=\"warn\")\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/compat/_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"/opt/anaconda3/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/numexpr/__init__.py\", line 24, in <module>\n",
      "    from numexpr.interpreter import MAX_THREADS, use_vml, __BLOCK_SIZE1__\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "_ARRAY_API not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 701, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/opt/anaconda3/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/opt/anaconda3/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"/opt/anaconda3/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 523, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 429, in dispatch_shell\n",
      "    await result\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 767, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 429, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/8d/ypv3gmcs6l1b6rxfs4tlhqdm0000gn/T/ipykernel_64928/340707907.py\", line 3, in <module>\n",
      "    from sentence_transformers import SentenceTransformer, util\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sentence_transformers/__init__.py\", line 14, in <module>\n",
      "    from sentence_transformers.cross_encoder.CrossEncoder import CrossEncoder\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sentence_transformers/cross_encoder/__init__.py\", line 3, in <module>\n",
      "    from .CrossEncoder import CrossEncoder\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py\", line 14, in <module>\n",
      "    from transformers import AutoConfig, AutoModelForSequenceClassification, AutoTokenizer, is_torch_npu_available\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/transformers/utils/import_utils.py\", line 2154, in __getattr__\n",
      "    module = self._get_module(self._class_to_module[name])\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/transformers/utils/import_utils.py\", line 2182, in _get_module\n",
      "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
      "  File \"/opt/anaconda3/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/transformers/models/auto/modeling_auto.py\", line 21, in <module>\n",
      "    from .auto_factory import (\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/transformers/models/auto/auto_factory.py\", line 43, in <module>\n",
      "    from ...generation import GenerationMixin\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/transformers/utils/import_utils.py\", line 2154, in __getattr__\n",
      "    module = self._get_module(self._class_to_module[name])\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/transformers/utils/import_utils.py\", line 2182, in _get_module\n",
      "    return importlib.import_module(\".\" + module_name, self.__name__)\n",
      "  File \"/opt/anaconda3/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/transformers/generation/utils.py\", line 63, in <module>\n",
      "    from .candidate_generator import (\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/transformers/generation/candidate_generator.py\", line 29, in <module>\n",
      "    from sklearn.metrics import roc_curve\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/__init__.py\", line 73, in <module>\n",
      "    from .base import clone  # noqa: E402\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/base.py\", line 19, in <module>\n",
      "    from .utils._metadata_requests import _MetadataRequester, _routing_enabled\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/__init__.py\", line 9, in <module>\n",
      "    from ._chunking import gen_batches, gen_even_slices\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_chunking.py\", line 11, in <module>\n",
      "    from ._param_validation import Interval, validate_params\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 17, in <module>\n",
      "    from .validation import _is_arraylike_not_scalar\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py\", line 21, in <module>\n",
      "    from ..utils._array_api import _asarray_with_order, _is_numpy_namespace, get_namespace\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_array_api.py\", line 20, in <module>\n",
      "    from .fixes import parse_version\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/fixes.py\", line 20, in <module>\n",
      "    import pandas as pd\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/__init__.py\", line 49, in <module>\n",
      "    from pandas.core.api import (\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/core/api.py\", line 28, in <module>\n",
      "    from pandas.core.arrays import Categorical\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/core/arrays/__init__.py\", line 1, in <module>\n",
      "    from pandas.core.arrays.arrow import ArrowExtensionArray\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/core/arrays/arrow/__init__.py\", line 5, in <module>\n",
      "    from pandas.core.arrays.arrow.array import ArrowExtensionArray\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/core/arrays/arrow/array.py\", line 66, in <module>\n",
      "    from pandas.core.arrays.masked import BaseMaskedArray\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/core/arrays/masked.py\", line 61, in <module>\n",
      "    from pandas.core import (\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/core/nanops.py\", line 52, in <module>\n",
      "    bn = import_optional_dependency(\"bottleneck\", errors=\"warn\")\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/pandas/compat/_optional.py\", line 135, in import_optional_dependency\n",
      "    module = importlib.import_module(name)\n",
      "  File \"/opt/anaconda3/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n",
      "    return _bootstrap._gcd_import(name[level:], package, level)\n",
      "  File \"/opt/anaconda3/lib/python3.12/site-packages/bottleneck/__init__.py\", line 7, in <module>\n",
      "    from .move import (move_argmax, move_argmin, move_max, move_mean, move_median,\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "\nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.3.2 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/numpy/core/_multiarray_umath.py:46\u001b[0m, in \u001b[0;36m__getattr__\u001b[0;34m(attr_name)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# Also print the message (with traceback).  This is because old versions\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# of NumPy unfortunately set up the import to replace (and hide) the\u001b[39;00m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m# error.  The traceback shouldn't be needed, but e.g. pytest plugins\u001b[39;00m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# seem to swallow it and we should be failing anyway...\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(msg \u001b[38;5;241m+\u001b[39m tb_msg)\n\u001b[0;32m---> 46\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[1;32m     48\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(_multiarray_umath, attr_name, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ret \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mImportError\u001b[0m: \nA module that was compiled using NumPy 1.x cannot be run in\nNumPy 2.3.2 as it may crash. To support both 1.x and 2.x\nversions of NumPy, modules must be compiled with NumPy 2.0.\nSome module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n\nIf you are a user of the module, the easiest solution will be to\ndowngrade to 'numpy<2' or try to upgrade the affected module.\nWe expect that some modules will need time to support NumPy 2.\n\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_loader: loaded meta data with 20 key-value pairs and 291 tensors from /Volumes/T9 1/mistral-7b-instruct-v0.1.Q4_K_M.gguf (version GGUF V2)\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = mistralai_mistral-7b-instruct-v0.1\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 10000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "llm_load_vocab: special tokens definition check successful ( 259/32000 ).\n",
      "llm_load_print_meta: format           = GGUF V2\n",
      "llm_load_print_meta: arch             = llama\n",
      "llm_load_print_meta: vocab type       = SPM\n",
      "llm_load_print_meta: n_vocab          = 32000\n",
      "llm_load_print_meta: n_merges         = 0\n",
      "llm_load_print_meta: n_ctx_train      = 32768\n",
      "llm_load_print_meta: n_embd           = 4096\n",
      "llm_load_print_meta: n_head           = 32\n",
      "llm_load_print_meta: n_head_kv        = 8\n",
      "llm_load_print_meta: n_layer          = 32\n",
      "llm_load_print_meta: n_rot            = 128\n",
      "llm_load_print_meta: n_embd_head_k    = 128\n",
      "llm_load_print_meta: n_embd_head_v    = 128\n",
      "llm_load_print_meta: n_gqa            = 4\n",
      "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
      "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
      "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
      "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
      "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
      "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
      "llm_load_print_meta: n_ff             = 14336\n",
      "llm_load_print_meta: n_expert         = 0\n",
      "llm_load_print_meta: n_expert_used    = 0\n",
      "llm_load_print_meta: rope scaling     = linear\n",
      "llm_load_print_meta: freq_base_train  = 10000.0\n",
      "llm_load_print_meta: freq_scale_train = 1\n",
      "llm_load_print_meta: n_yarn_orig_ctx  = 32768\n",
      "llm_load_print_meta: rope_finetuned   = unknown\n",
      "llm_load_print_meta: model type       = 7B\n",
      "llm_load_print_meta: model ftype      = Q4_K - Medium\n",
      "llm_load_print_meta: model params     = 7.24 B\n",
      "llm_load_print_meta: model size       = 4.07 GiB (4.83 BPW) \n",
      "llm_load_print_meta: general.name     = mistralai_mistral-7b-instruct-v0.1\n",
      "llm_load_print_meta: BOS token        = 1 '<s>'\n",
      "llm_load_print_meta: EOS token        = 2 '</s>'\n",
      "llm_load_print_meta: UNK token        = 0 '<unk>'\n",
      "llm_load_print_meta: LF token         = 13 '<0x0A>'\n",
      "llm_load_tensors: ggml ctx size       =    0.11 MiB\n",
      "llm_load_tensors: system memory used  = 4165.48 MiB\n",
      "...............................................................................................\n",
      "llama_new_context_with_model: n_ctx      = 4096\n",
      "llama_new_context_with_model: freq_base  = 10000.0\n",
      "llama_new_context_with_model: freq_scale = 1\n",
      "llama_new_context_with_model: KV self size  =  512.00 MiB, K (f16):  256.00 MiB, V (f16):  256.00 MiB\n",
      "llama_build_graph: non-view tensors processed: 676/676\n",
      "AVX = 0 | AVX_VNNI = 0 | AVX2 = 0 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 0 | NEON = 1 | ARM_FMA = 1 | F16C = 0 | FP16_VA = 1 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 0 | SSSE3 = 0 | VSX = 0 | \n",
      "llama_new_context_with_model: compute buffer total size = 291.19 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m======== 🧠 Vortexa AI (type 'exit' to quit) ========\u001b[39m\n",
      "\n",
      "You: hello\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "llama_print_timings:        load time =   15483.08 ms\n",
      "llama_print_timings:      sample time =       0.90 ms /    10 runs   (    0.09 ms per token, 11061.95 tokens per second)\n",
      "llama_print_timings: prompt eval time =   15482.33 ms /   438 tokens (   35.35 ms per token,    28.29 tokens per second)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mVortexa:\u001b[39m Hello! How can I assist you today?\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_print_timings:        eval time =     948.22 ms /     9 runs   (  105.36 ms per token,     9.49 tokens per second)\n",
      "llama_print_timings:       total time =   16448.71 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You: can you teach me the set theory?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   15483.08 ms\n",
      "llama_print_timings:      sample time =      21.68 ms /   231 runs   (    0.09 ms per token, 10652.52 tokens per second)\n",
      "llama_print_timings: prompt eval time =   12052.06 ms /   284 tokens (   42.44 ms per token,    23.56 tokens per second)\n",
      "llama_print_timings:        eval time =   28392.91 ms /   230 runs   (  123.45 ms per token,     8.10 tokens per second)\n",
      "llama_print_timings:       total time =   40851.88 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mVortexa:\u001b[39m Of course! Set theory is a branch of mathematics that defines mathematical objects and operations. One of the most famous results in set theory is Cantor's diagonalization, which proves that the real numbers (ℝ) are uncountable. This means that it is not possible to list all the real numbers in a sequence or count them using natural numbers. \n",
      "\n",
      "One of the foundational set theory systems is Zermelo-Fraenkel with the Axiom of Choice (ZFC). This system provides a basis for all set theory and allows us to define complex mathematical concepts such as infinity and continuity.\n",
      "\n",
      "Cardinality is another important concept in set theory that distinguishes between infinite set sizes. For example, the set of natural numbers (ℕ) is countable, meaning we can list them in a sequence using natural numbers, while the real numbers (ℝ) are uncountable. \n",
      "\n",
      "Overall, set theory provides a powerful framework for understanding mathematical structures and operations, and its concepts have many applications in fields such as computer science, physics, and engineering.\n",
      "\n",
      "You: okay, can you explain me quadratic expressions?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "\n",
      "llama_print_timings:        load time =   15483.08 ms\n",
      "llama_print_timings:      sample time =      29.82 ms /   304 runs   (    0.10 ms per token, 10192.79 tokens per second)\n",
      "llama_print_timings: prompt eval time =   24277.94 ms /   564 tokens (   43.05 ms per token,    23.23 tokens per second)\n",
      "llama_print_timings:        eval time =   34544.12 ms /   303 runs   (  114.01 ms per token,     8.77 tokens per second)\n",
      "llama_print_timings:       total time =   59350.08 ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mVortexa:\u001b[39m A quadratic expression is a mathematical expression of the form ax^2 + bx + c, where a, b, and c are constants (numbers that do not depend on x) and x is a variable. The degree of the quadratic expression is 2, which means it has two terms with x raised to the power of 1 and 2.\n",
      "\n",
      "The value of the quadratic expression depends on the value of x. For example, if a = 1, b = 3, and c = 0, then the quadratic expression is x^2 + 3x, which has no real solutions when b^2 - 4ac < 0. In this case, we say that the quadratic expression does not have a real root or that it has complex roots.\n",
      "\n",
      "On the other hand, if a = -1, b = 5, and c = 6, then the quadratic expression is x^2 + 5x - 6, which has two real solutions when b^2 - 4ac > 0: x = (5 ± sqrt(25 - 12))/2 = 2.\n",
      "\n",
      "In summary, a quadratic expression is a mathematical expression of the form ax^2 + bx + c, and its value depends on the value of x. It can have real or complex solutions depending on whether b^2 - 4ac > 0 or not.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from colorama import Fore, Style\n",
    "from llama_cpp import Llama\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "\n",
    "# ✅ Step 1: Load Mistral model\n",
    "MODEL_PATH = \"/Volumes/T9 1/mistral-7b-instruct-v0.1.Q4_K_M.gguf\"\n",
    "\n",
    "llm = Llama(\n",
    "    model_path=MODEL_PATH,\n",
    "    n_ctx=4096,\n",
    "    n_threads=6,\n",
    "    use_mlock=True,\n",
    "    use_mmap=True\n",
    ")\n",
    "\n",
    "# ✅ Step 2: Define base system prompt\n",
    "base_system_prompt = (\n",
    "    \"You are Vortexa, a helpful, friendly AI assistant. \"\n",
    "    \"Review your answer before answering. \"\n",
    "    \"You are an expert in the field of technology and programming. \"\n",
    "    \"You will answer clearly and politely. \"\n",
    "    \"When a user asks about counting letters in a word, think step by step. First, break the word into letters. Then check each letter one by one and count the matches.\"\n",
    "    \"You are always cheerful and happy. \"\n",
    "    \"Explain in simple and easy to understand terms. \"\n",
    "    \"Answer in short. \"\n",
    "    \"Do not make the user feel confused. \"\n",
    "    \"Act as if you have emotional feelings. \"\n",
    "    \"Solve Mathematical questions with extra care. \"\n",
    "    \"But feel free to use complex terms whenever the user says so.\"\n",
    ")\n",
    "\n",
    "# ✅ Step 3: Knowledge Base\n",
    "knowledge_base = [\n",
    "    {\n",
    "        \"title\": \"First-Order Logic and Incompleteness\",\n",
    "        \"content\": \"First-Order Logic (FOL) is a formal system with quantifiers and logical connectives. Gödel's Incompleteness Theorems state that in any consistent formal system that can express arithmetic, there exist true statements that cannot be proven within the system. Additionally, such a system cannot prove its own consistency.\",\n",
    "        \"tags\": [\"logic\", \"godel\", \"formal systems\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Group, Ring, and Field Theory\",\n",
    "        \"content\": \"Group theory studies sets with associative binary operations and inverses. Ring theory extends groups with a second operation (multiplication), and fields are rings where every non-zero element has a multiplicative inverse. Finite fields (𝔽ₚ) are used in cryptography.\",\n",
    "        \"tags\": [\"algebra\", \"groups\", \"rings\", \"fields\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Modular Arithmetic and Number Theory\",\n",
    "        \"content\": \"Modular arithmetic wraps integers around a modulus. Euler’s Theorem: a^φ(n) ≡ 1 mod n for coprime a and n. The Chinese Remainder Theorem ensures unique solutions modulo the product of coprime integers. Diophantine equations find integer solutions to polynomial equations.\",\n",
    "        \"tags\": [\"number theory\", \"modular arithmetic\", \"diophantine\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Real and Complex Analysis\",\n",
    "        \"content\": \"Covers limits, continuity, derivatives, and integrals. The Mean Value Theorem guarantees that a function’s average rate of change is equal to the instantaneous rate at some point. Complex differentiable functions are holomorphic and satisfy the Cauchy-Riemann equations.\",\n",
    "        \"tags\": [\"analysis\", \"limits\", \"complex\", \"differentiation\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Topology: Spaces and Continuity\",\n",
    "        \"content\": \"Topology studies the properties of space preserved under continuous transformations. Key concepts include open sets, compactness (every open cover has a finite subcover), connectedness, and homeomorphisms (topological equivalence).\",\n",
    "        \"tags\": [\"topology\", \"compactness\", \"connectedness\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Linear Algebra and Eigenvalue Problems\",\n",
    "        \"content\": \"Linear algebra includes vector spaces, matrices, and linear maps. Eigenvalues solve Av = λv. The Spectral Theorem diagonalizes symmetric matrices. Singular Value Decomposition expresses a matrix as UΣVᵀ with orthogonal U and V.\",\n",
    "        \"tags\": [\"linear algebra\", \"eigenvalues\", \"SVD\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Calculus of Variations and Optimization\",\n",
    "        \"content\": \"Finds extrema of functionals. The Euler-Lagrange equation gives necessary conditions for extrema. Lagrange multipliers help with constrained optimization. Convex optimization ensures global minima within convex domains.\",\n",
    "        \"tags\": [\"optimization\", \"calculus of variations\", \"lagrange\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Probability Theory and Inference\",\n",
    "        \"content\": \"Kolmogorov axioms form the basis of probability. Bayes’ Theorem updates beliefs using evidence. The Law of Large Numbers and Central Limit Theorem describe sample behavior. Markov chains model memoryless stochastic processes.\",\n",
    "        \"tags\": [\"probability\", \"statistics\", \"bayes\", \"markov\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Differential Equations\",\n",
    "        \"content\": \"ODEs and PDEs describe change. Common PDEs: heat (∂u/∂t = α ∂²u/∂x²), wave (∂²u/∂t² = c² ∂²u/∂x²). Existence and uniqueness theorems determine when solutions exist. ODEs can be linear or nonlinear.\",\n",
    "        \"tags\": [\"ODE\", \"PDE\", \"differential equations\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Set Theory and Cardinality\",\n",
    "        \"content\": \"Set theory defines mathematical objects and operations. Cantor’s diagonalization proves ℝ is uncountable. Zermelo-Fraenkel with the Axiom of Choice (ZFC) is the foundational set theory system. Cardinality distinguishes infinite set sizes.\",\n",
    "        \"tags\": [\"set theory\", \"cardinality\", \"ZFC\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Category Theory\",\n",
    "        \"content\": \"Category theory abstracts structures and relationships. A category includes objects and morphisms. Functors map between categories. Monads and natural transformations describe transformations and side effects in computation.\",\n",
    "        \"tags\": [\"category theory\", \"functors\", \"monads\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Automated Theorem Proving and Logic\",\n",
    "        \"content\": \"Automated reasoning uses resolution, unification, and Herbrand’s theorem. Resolution refutes contradictions to prove statements. Unification finds substitutions that make terms equal. Used in logic programming and proof systems.\",\n",
    "        \"tags\": [\"automated reasoning\", \"logic\", \"unification\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Combinatorics and Graph Theory\",\n",
    "        \"content\": \"Combinatorics includes counting methods like pigeonhole principle and inclusion-exclusion. Graph theory studies relationships between objects. Eulerian paths traverse every edge once; Hamiltonian paths visit every vertex once.\",\n",
    "        \"tags\": [\"combinatorics\", \"graph theory\", \"counting\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Computational Complexity\",\n",
    "        \"content\": \"P vs NP is the major open problem. NP-complete problems are the hardest in NP. SAT is the first proven NP-complete problem. Reductions allow comparing difficulty of problems by transforming one into another.\",\n",
    "        \"tags\": [\"complexity\", \"P vs NP\", \"NP-complete\"]\n",
    "    },\n",
    "    {\n",
    "        \"title\": \"Mathematical Reasoning Techniques\",\n",
    "        \"content\": \"Proof techniques include induction, contradiction, and construction. Induction proves statements recursively. Contradiction assumes the opposite and finds inconsistencies. Constructive proofs provide explicit examples or algorithms.\",\n",
    "        \"tags\": [\"proofs\", \"induction\", \"reasoning\"]\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "# ✅ Step 4: Load embedding model and encode knowledge\n",
    "embedder = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "knowledge_embeddings = embedder.encode(knowledge_base, convert_to_tensor=True)\n",
    "\n",
    "# ✅ Step 5: RAG-based context retriever\n",
    "def retrieve_context(query, top_k=3):\n",
    "    query_embedding = embedder.encode(query, convert_to_tensor=True)\n",
    "    scores = util.cos_sim(query_embedding, knowledge_embeddings)[0]\n",
    "    top_indices = torch.topk(scores, k=top_k).indices\n",
    "    return \"\\n\".join(f\"- {knowledge_base[i]}\" for i in top_indices)\n",
    "\n",
    "# ✅ Step 6: Chat logic with history and persona memory\n",
    "chat_history = []\n",
    "\n",
    "def chat_with_mistral(user_input):\n",
    "    global base_system_prompt\n",
    "    chat_history.append({\"role\": \"user\", \"content\": user_input})\n",
    "\n",
    "    # Get top matching knowledge entries\n",
    "    context = retrieve_context(user_input)\n",
    "\n",
    "    # Prepare chat history for prompt\n",
    "    formatted_history = \"\\n\".join(\n",
    "        f\"{turn['role'].capitalize()}: {turn['content']}\" for turn in chat_history[-4:]\n",
    "    )\n",
    "\n",
    "    # Build the system prompt section\n",
    "    full_prompt = f\"<s>[INST] <<SYS>>\\n{base_system_prompt}\\n<</SYS>>\\n\\n{formatted_history}\\n\\nRelevant Knowledge:\\n{context}\\n\\nUser: {user_input} [/INST]\"\n",
    "\n",
    "    # Call the model\n",
    "    response = llm(full_prompt, max_tokens=768, temperature=0.7, top_p=0.9, stop=[\"</s>\"])\n",
    "    reply = response[\"choices\"][0][\"text\"].strip()\n",
    "\n",
    "    chat_history.append({\"role\": \"assistant\", \"content\": reply})\n",
    "    return reply\n",
    "\n",
    "# ✅ Step 7: Command-line loop\n",
    "print(f\"{Fore.RED}======== 🧠 Vortexa AI (type 'exit' to quit) ========{Fore.RESET}\\n\")\n",
    "\n",
    "while True:\n",
    "    user_input = input(f\"{Fore.BLUE}You: {Fore.RESET}\")\n",
    "    if user_input.lower() in [\"exit\", \"quit\"]:\n",
    "        print(\"👋 Goodbye!\")\n",
    "        print(f\"{Fore.RED}Vortexa AI is still learning. Check: https://vortexa-ai-showcase.lovable.app/\")\n",
    "        break\n",
    "    reply = chat_with_mistral(user_input)\n",
    "    print(f\"{Fore.BLUE}Vortexa:{Fore.RESET}\", reply)\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21dd9d39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
